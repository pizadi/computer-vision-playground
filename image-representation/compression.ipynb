{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5b7f4a5-9dda-44bb-b561-e2121c407d1d",
   "metadata": {},
   "source": [
    "# Basics of Compression\n",
    "In this notebook, we will look at the basics of compression. This notebook is mostly aimed at giving you an understanding of concepts such as entropy, and various encoding methods.\n",
    "\n",
    "In the applied compression notebook, we will look at some methods for lossless and lossy compression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd37c2c-8978-4e61-8376-81a83a124ca1",
   "metadata": {},
   "source": [
    "## Section 0. Preparing the Notebook\n",
    "We start by importing the necessary libraries and then loading a sample image to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c477f76-c6e9-445c-b76d-0a6cb66eeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798aafa-862c-43db-949d-d96a8dad1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import bitarray as bt\n",
    "from solutions import *\n",
    "from utils import *\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e6ed4b-c6b0-47d2-9da4-ffcc2fbab2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the sample image and setting the colormap for pyplot\n",
    "image = cv.imread('data/baboon.bmp', cv.IMREAD_GRAYSCALE)\n",
    "plt.set_cmap('Greys_r')\n",
    "_ = plt.imshow(image), plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355d611-c6bc-4de4-bf2b-c569091601b2",
   "metadata": {},
   "source": [
    "## Section 1. Encoding Redundency\n",
    "To understand how changing our method of encoding might help us, let us do a little thought experiment first. We begin by drawing the histogram of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11bbc3-8313-492a-b189-52bc8e9d73df",
   "metadata": {},
   "source": [
    "### Section 1.1. Introduction to Huffman Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bb9c8f-09d7-4e50-9fec-c87ad0d923b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawHist(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4a462-cac4-4f54-aa94-cb227a348671",
   "metadata": {},
   "source": [
    "As you can see, nearly half of the bins are unused. Normally we use 8-bit codewords for each intensity level, to keep the 256 possible intensity levels. But here we can *almost* get away with using 7-bit codewords for almost every bin. Let's say that we want to manually implement such a coding scheme. One way would be to take the 127 first possible codewords and assign to them the 127 most frequent intensity levels. The last codeword, i.e. $1111111$, will be split into the two codewords $11111110$ and $11111111$ and assigned to the two least frequent intensity levels, giving us codewords for all the 129 non-zero bins in the image.\n",
    "\n",
    "Using such a coding scheme for writing data is pretty straightforward; you can simply replace each intensity level with its corresponding codeword. For interpreting the generated datastream as an image, we can simply start by reading the stream, 7-bit at a time. If we reach a septet equal to $1111111$, we can simply add the next bit to it, and interpret the resulting 8-bit codeword.\n",
    "\n",
    "Try and create such a code for the baboon image. Use the *bitarray* library to generate the bitcode, and compare its length to the original bitcode.\n",
    "\n",
    "You can read more about the *bitarray* library [here](https://pypi.org/project/bitarray/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28893844-3f77-4de3-9fb5-f163b1ff604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = image.shape\n",
    "byte_array = image.flatten()\n",
    "\n",
    "# ====== YOUR CODE ======\n",
    "\n",
    "bitarray_compressed = None\n",
    "bitarray_compressed_reference = baboonCompress(image)\n",
    "\n",
    "# Comparing the bit lengths of the different representations\n",
    "print(f'Bit length of the original image: {image.size * 8}')\n",
    "print(f'Bit length of your compressed image: {len(bitarray_compressed)}')\n",
    "print(f'Bit length of the reference compressed image: {len(bitarray_compressed_reference)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac4de1-dc5b-4cdb-80c6-14ada775d70c",
   "metadata": {},
   "source": [
    "As you can see, using a different encoding resulted in a considerable reduction in the size of the image, without damaging the contents in any way. You can still recreate the original image using the provided bitcode, if you have the encoding dictionary. Of course, storing the dictionary along with the image will increase the size of the file, but with images that are sufficiently large, or have relatively high coding redundency, the size of this dictionary will be much lower than the decrease in size caused by our method of encoding.\n",
    "\n",
    "We can expand our naive method to further reduce the necessary bit length for representing an image. One way of achieving this is by Huffman encoding. Below is a simple method of creating a Huffman encoding for a 5-symbol piece of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c0b630-d4d7-439e-9ad6-5c43af13a4d5",
   "metadata": {},
   "source": [
    "Imagine that we have a string of data, composed of the 5 symbols *A*, *B*, *C*, *D*, and *E*. The prevalence of these 5 symbols is as follows:\n",
    "\n",
    "$\n",
    "p_A = 0.33,\n",
    "p_B = 0.33,\n",
    "p_C = 0.17,\n",
    "p_D = 0.09,\n",
    "p_E = 0.08\n",
    "$\n",
    "\n",
    "We can start by creating a combined symbol *DE*, composed of the two least-probable symbols in our tables, and with a prevalence of *0.17*. Each time that we encounter a *D* or an *E* in our data, we put the encoding value for *DE* in the bit-array, followed by a *0* if the original symbol was a *D*, and a *1* if it was an *E*. We repeat this process with the two least probable symbols to create a combined symbol *CDE* with the probability 0.34. We continue this operation until we arrive at a combined symbol *ABCDE*. This symbol can be decoded according to the following graph.\n",
    "\n",
    "![A representation of the proposed Huffman code](./figures/huffman_code.png)\n",
    "\n",
    "The equivalent codeword for each symbol is the string of bits that mark its path from the tree's root, e.g. the codeword for A is *00*, D is *110*, etc. For decoding, we simply start traversing the tree according to the received bitcode, until we reach a leaf node. Therefore, *0001110* can be decoded as *ABD*.\n",
    "\n",
    "This method is known as Huffman coding, and can be used to decrease the data size when there is a imbalance in the distribution of the source symbols. Here, we encode an image which uses most of the pixel intensities, to show that even then, a different method of encoding can be helpful in decreasing the size of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a3296-e8b5-45d2-8640-7f2d1da5a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the new image and\n",
    "image = cv.imread('data/barbara.bmp', cv.IMREAD_GRAYSCALE)\n",
    "_ = plt.imshow(image), plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac24e60-179c-456a-b616-6b36bf5d726a",
   "metadata": {},
   "source": [
    "The *bitarray* library itself has built-in functions for Huffman coding, which you can see in action below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799015ca-2ea7-4ca7-b358-da07861b54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray.util import canonical_huffman, canonical_decode\n",
    "\n",
    "# Extracting the frequencies for the sample image\n",
    "symbols = list(range(256))\n",
    "frequencies = (np.histogram(image, bins=256, range=(-.5, 255.5))[0]).tolist()\n",
    "\n",
    "# Creating a Huffman encoding/decoding dictionary\n",
    "huffman_dict, count, symbol_canonical = canonical_huffman({i : frequencies[i] for i in range(256)})\n",
    "\n",
    "# Encoding the image data\n",
    "image_encoded = bt.bitarray()\n",
    "for pixel in image.flatten():\n",
    "    image_encoded += huffman_dict[pixel]\n",
    "\n",
    "# Comparing the length of the encoded and raw data\n",
    "print(f'Bit length of the raw image: {image.size * 8}')\n",
    "print(f'Bit length of the encoded image: {len(image_encoded)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf1ed4-4fb3-4787-91df-a28cf769b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding the bitstring\n",
    "decoded_image = canonical_decode(image_encoded, count, symbol_canonical)\n",
    "decoded_image = np.array(list(decoded_image), dtype=np.uint8).reshape(image.shape)\n",
    "_ = plt.imshow(decoded_image), plt.axis('off'), plt.title('Decoded Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab65327-fc13-4491-8117-deea56d5ae36",
   "metadata": {},
   "source": [
    "### Section 1.2. What is Entropy?\n",
    "Entropy, as it is defined in information theory, can be described as the amount of *'information'* that a piece of data (string of bits, scribbles on a piece of paper, or what the weatherman says on TV) contains, and it represents a lower bound on how much we can compress the said data. A better understanding of entropy can be achieved by studying books on information theory, such as *Elements of Information Theory* by *Thomas M. Cover* and *Joy A. Thomas*.\n",
    "\n",
    "For this notebook, we will try to avoid delving into the more complex side of information theory. But there is one formula that you ought to keep in mind, which is the basic formula for calculating the entropy in a piece of data, e.g. in a pixel. Let's say that in an image or a series of images, we count the number of times that each intensity value is represented, and create a probabilistic distribution function for all 255 intensity values.\n",
    "\n",
    "$\n",
    "\\sum_{z = 0}^{255} p_{(z)} = 1\n",
    "$\n",
    "\n",
    "We can calculate the average entropy of a pixel with the following formula.\n",
    "\n",
    "$\n",
    "- \\sum_{z = 0}^{255} p_{(z)} . log_2 p_{(z)}\n",
    "$\n",
    "\n",
    "You can try to calculate this for a variety of distributions. The highest entropy happens for the case where every pixel has about the same probability of appearing, where the average entropy will be 8 bits. For every other unbalanced distribution, the entropy will be lower than 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b14a9e0-3c8d-44e8-9095-6d246de13e8e",
   "metadata": {},
   "source": [
    "### Section 1.3. Entropy in Images\n",
    "Note that the formula above assumes that every pixel's value is independent from the pixels around it, i.e. each pixel is generated randomly from a certain probability distribution. However, we know that this is not the case, since the value of pixels is often close to the pixels around them. Imagine that instead of saving the pixel intensities, we saved each pixel's difference with the pixel on its left. Doing so would certainly decrease the entropy greatly, since most of the values would be close to zero.\n",
    "\n",
    "After doing this, we can then decode the image by saving the rightmost column of pixels, and creating every column from the difference map that we have. Try doing so below, and compare the achieved compression with the compression achieved by treating the pixel intensities as statistically independent. In the provided solution, the right column is not compressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc7681-49ce-4f09-b18d-2f7a7f7ccc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffCompress(image : np.ndarray) -> Tuple[bt.bitarray, int, Tuple[Dict, List, List]]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - image : np.ndarray\n",
    "        A greyscale image, with dtype=np.uint8.\n",
    "    Returns:\n",
    "    - output : bt.bitarray\n",
    "        The compressed version of the image, using Huffman coding\n",
    "        and calculating the difference map.\n",
    "    - height : int\n",
    "        The height of the image, used to extract the rightmost\n",
    "        column.\n",
    "    - huffman : Tuple[Dict, List, List]\n",
    "        The output of the canonical_huffman function.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Encoding the image\n",
    "image_encoded_diff, height, huffman =  diffCompress(image)\n",
    "image_encoded_diff_ref, height_ref, huffman_ref =  diffCompressRef(image)\n",
    "\n",
    "# Comparing the sizes of raw and encoded images\n",
    "print(f'Bit length of the raw image: {image.size * 8}')\n",
    "print(f'Bit length of the encoded image, assuming independent pixel values): {len(image_encoded)}')\n",
    "print(f'Bit length of the encoded image, by encoding difference values: {len(image_encoded_diff)}')\n",
    "print(f'Bit length of the encoded image, by encoding difference values (reference): {len(image_encoded_diff_ref)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e648159-8951-4a4f-9474-b2eadec198c6",
   "metadata": {},
   "source": [
    "# Scratchpad\n",
    "You can use this section to try out different codes, without making a mess of the notebook. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d424c4-2045-4655-ad63-5419e7bf4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.size * 8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
