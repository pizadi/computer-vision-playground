{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56baf9de-4fde-4a4e-ac04-9f93c77fbe1c",
   "metadata": {},
   "source": [
    "# Spatial Filtering\n",
    "In this notebook, we will go through some basic methods of image filtering in the spatial domain.\n",
    "\n",
    "There will be a brief description of each method in the notebook, but you are encouraged to research each method yourself and try it on different images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b4db1-b6b5-4edc-b984-27ea4ab158c6",
   "metadata": {},
   "source": [
    "## Section 0. Preparing the Notebook\n",
    "We start by importing the necessary libraries and then loading a sample image to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1c62c-c8d9-4c34-9693-76922de9a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1bdff9-295c-438c-8bdc-c3631177974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from solutions import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393fd8ab-18fb-44ed-aeff-1612819355da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the sample image and setting the colormap for pyplot\n",
    "image = np.float64(cv.imread('data/man.bmp', cv.IMREAD_GRAYSCALE) / 255)\n",
    "plt.set_cmap('Greys_r')\n",
    "_ = plt.imshow(image), plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b246a-de5d-430b-bfa6-0532dd573e38",
   "metadata": {},
   "source": [
    "## Section 1. What is a Kernel?\n",
    "A very basic concept in spatial image filtering is a kernel. A kernel in its simplest form is a matrix which we slide across the different pixels in the image. In each position, the values of the kernel and the image are multiplied together, and the sum of these values will be the output for that position. In mathematics, this operation is called a correlation and is denoted by $ \\circledast $. Below is an example of this operation:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    1 & 3 & 5 & 6 \\\\\n",
    "    2 & 5 & 1 & 8 \\\\\n",
    "    2 & 3 & 5 & 9 \\\\\n",
    "    1 & 4 & 4 & 6\n",
    "\\end{bmatrix}\n",
    "\\circledast \n",
    "\\frac{1}{9} \\cdot\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 \n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "3 & 5 \\\\\n",
    "3 & 5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "What we did here, was averaging over a $3 \\times 3 $ window, which is commonly known as average or mean filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff9920-88bb-450b-a67d-26a18a148e52",
   "metadata": {},
   "source": [
    "### Section 1.1. Implementing a mean filter\n",
    "Now, write a piece of code which creates a mean kernel, and applies it to the sample image. Try the mean filter with different kernel sizes and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01de681-135d-42ca-9986-680cacbd397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a mean kernel constructor\n",
    "def meanKernel(kernel_size : Iterable[int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - kernel_size : Iterable[int, int]\n",
    "        An Iterable of two integers, which determines the size of the kernel.\n",
    "    Returns:\n",
    "    - kernel : np.ndarray\n",
    "        A mean kernel in np.ndarray format, with the specified size,\n",
    "        and with dtype=np.float64.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Creating the kernels and applying the filter\n",
    "kernel_size = (5, 5)\n",
    "kernel = meanKernel(kernel_size)\n",
    "kernel_ref = meanKernelRef(kernel_size)\n",
    "image_filtered = cv.filter2D(image, cv.CV_64F, kernel)\n",
    "image_filtered_ref = cv.filter2D(image, cv.CV_64F, kernel_ref)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "_ = plt.subplot(1, 3, 1), plt.imshow(image_filtered, vmin=0, vmax=1), plt.axis('off'), plt.title('Your output')\n",
    "_ = plt.subplot(1, 3, 2), plt.imshow(image_filtered_ref, vmin=0, vmax=1), plt.axis('off'), plt.title('Reference output')\n",
    "_ = plt.subplot(1, 3, 3), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76632f-11d1-46d1-8a30-8303f2cee697",
   "metadata": {},
   "source": [
    "### Section 1.2. Implementing a gaussian filter\n",
    "In the previous section, you saw that the mean filter, while removing the fine details, also blurs the important parts of the image, such as the edges of the buildings. A type of kernel which does less damage to edges is the gaussian kernel. The coefficients of a gaussian kernel $ G $ with the center $ c $ can be described by integrating over the familiar gaussian distribution formula:\n",
    "\n",
    "$ G_{(i,j)} = \\large \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\cdot \\exp(-\\frac{(i - c_i)^2 + (j - c_j)^2 }{\\sigma^2}) $\n",
    "\n",
    "Here is a sample $ 3 \\times 3 $ gaussian kernel with $ \\sigma = 1 $.\n",
    "\n",
    "$\n",
    "G = \n",
    "\\begin{bmatrix}\n",
    "0.075 & 0.124 & 0.075 \\\\\n",
    "0.124 & 0.204 & 0.124 \\\\\n",
    "0.075 & 0.124 & 0.075\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Using openCV, you can get a 1-D gaussian kernel by calling the ``getGaussianKernel`` function. Use this to create a gaussian kernel like the one described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28480736-7a0b-4f09-b954-ecfeee159718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a gaussian kernel constructor\n",
    "def gaussianKernel(kernel_size : Iterable[int], sigma : float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - kernel_size : Iterable[int]\n",
    "        An Iterable of two integers, which determines the size of the kernel.\n",
    "    - sigma : float\n",
    "        The sigma parameter in the gaussian distribution.\n",
    "    Returns:\n",
    "    - kernel : np.ndarray\n",
    "        A gaussian kernel in np.ndarray format, with the specified size,\n",
    "        and with dtype=np.float64.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Creating the kernels and applying the filter\n",
    "kernel_size = (5, 5)\n",
    "sigma = 2\n",
    "kernel = gaussianKernel(kernel_size, sigma)\n",
    "kernel_ref = gaussianKernelRef(kernel_size, sigma)\n",
    "image_filtered = cv.filter2D(image, cv.CV_64F, kernel)\n",
    "image_filtered_ref = cv.filter2D(image, cv.CV_64F, kernel_ref)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(18, 6))\n",
    "_ = plt.subplot(1, 3, 1), plt.imshow(image_filtered, vmin=0, vmax=1), plt.axis('off'), plt.title('Your output')\n",
    "_ = plt.subplot(1, 3, 2), plt.imshow(image_filtered_ref, vmin=0, vmax=1), plt.axis('off'), plt.title('Reference output')\n",
    "_ = plt.subplot(1, 3, 3), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d45559-3e4b-4007-8be8-0c15385ac221",
   "metadata": {},
   "source": [
    "## Section 2. Edge Detection Filters\n",
    "The mean and gaussian filters above mostly serve to remove details from an image. However, we can use spatial filtering to extract details from an image, e.g. the edges of objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6defcb1-276b-4852-a20b-fac28b59dff5",
   "metadata": {},
   "source": [
    "### Section 2.1. First-Derivative Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc05f58-d702-4656-827e-7bceaf2f7e49",
   "metadata": {},
   "source": [
    "#### Section 2.1.1 Basic First-Derivative Filters\n",
    "A very simple way to detect edges, i.e. the areas where there is a sudden change in pixel intensity levels, is by calculating the derivative of an image along a certain axis. There are several derivative kernels that we can use:\n",
    "\n",
    "\n",
    "![Derivative Kernels](figures/derivative_kernels.jpg \"Derivative Kernels\")\n",
    "\n",
    "Implement some of these kernels below and observe the output edge map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30b9241-9483-470a-a962-1ebbeda64af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a derivative kernel constructor\n",
    "def derivateKernel(direction : str, mode : str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - direction : ['h' | 'v']\n",
    "        Determines the axis along which derivation takes place. 'h' for horizontal\n",
    "        and 'v' for vertical differentiation.\n",
    "    - mode : ['c' | 'f']\n",
    "        Determines the type of differentiation. 'c' for central difference, and 'f'\n",
    "        for forward difference.\n",
    "    Returns:\n",
    "    - kernel : np.ndarray\n",
    "        A derivative kernel in np.ndarray format, with the specified \n",
    "        characteristics and with dtype=np.float64.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Creating the kernels and applying the filter\n",
    "direction = 'v'\n",
    "mode = 'f'\n",
    "kernel = derivateKernel(direction, mode)\n",
    "kernel_ref = derivateKernelRef(direction, mode)\n",
    "edge_map = cv.filter2D(image, cv.CV_64F, kernel)\n",
    "edge_map_ref = cv.filter2D(image, cv.CV_64F, kernel_ref)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(18, 6))\n",
    "_ = plt.subplot(1, 3, 1), plt.imshow(edge_map, vmin=-1, vmax=1), plt.axis('off'), plt.title('Your Derivative Map')\n",
    "_ = plt.subplot(1, 3, 2), plt.imshow(edge_map_ref, vmin=-1, vmax=1), plt.axis('off'), plt.title('Reference Derivative Map')\n",
    "_ = plt.subplot(1, 3, 3), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616447d-bfa3-49fd-8a50-ad58737c457a",
   "metadata": {},
   "source": [
    "As you can see, the edge map has a gray-ish tone, since the minimum intensity for pixels is now $ -1 $ instead of $ 0 $, and therefore smooth areas in the original image look gray in the intensity map. We can use the absolute value of the map to show a pure representation of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a882b3-9739-4c0b-aa1b-c3f667653773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the absolute value of the maps\n",
    "edge_map = np.abs(edge_map)\n",
    "edge_map_ref = np.abs(edge_map_ref)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(18, 6))\n",
    "_ = plt.subplot(1, 3, 1), plt.imshow(edge_map), plt.axis('off'), plt.title('Magnitude of Your Derivative Map')\n",
    "_ = plt.subplot(1, 3, 2), plt.imshow(edge_map_ref), plt.axis('off'), plt.title('Magnitude of Reference Derivative Map')\n",
    "_ = plt.subplot(1, 3, 3), plt.imshow(image), plt.axis('off'), plt.title('Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc4c1b-24b9-43bf-aa13-11ed6113526c",
   "metadata": {},
   "source": [
    "However, by doing so we have destroyed the data about the direction of the edges, meaning that we no longer know whether a certain point in the edge map shows a bright-to-dark or a dark-to-bright transition. Also, notice that we have only gathered the edges along a certain direction in our edge map. One way of dealing with this issue is by dividing the edge data into two maps of edge *magnitude* and *orientation*. You might also hear the term *gradient map* used for this representation.\n",
    "\n",
    "For two derivate functions $ d_x $ and $ d_y $, the magnitude and orientation of the gradient $ G $ can be calculated as follows:\n",
    "\n",
    "$\n",
    "{\\parallel G \\parallel}^2 = d_x^2 + d_y^2 \n",
    "$\n",
    "\n",
    "$\n",
    "\\angle G = atan({d_y},{d_x})\n",
    "$\n",
    "\n",
    "Using the derivative maps of an image, create a gradient map of the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c6feb8-1ee0-4131-b35a-0e306af305f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a gradient map constructor\n",
    "def gradientMap(image : np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - image : np.ndarray\n",
    "        An image in np.ndarray format, with dtype=np.float64.\n",
    "        \n",
    "    Returns\n",
    "    - gradient_magnitude : np.ndarray\n",
    "        An np.ndarray representation of gradient magnitudes, with dtype=np.float64.\n",
    "    - gradient_orientation : np.ndarray\n",
    "        An np.ndarray representation of gradient orientations. Values can range from\n",
    "        -pi to +pi. Should also have dtype=np.float64.\n",
    "    \n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Applying the filter\n",
    "gradient_magnitude, gradient_orientation = gradientMap(image)\n",
    "gradient_magnitude_ref, gradient_orientation_ref = gradientMapRef(image)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(15, 15))\n",
    "_ = plt.subplot(2, 2, 1), plt.imshow(gradient_magnitude), plt.axis('off'), plt.title('Your Gradient Magnitude')\n",
    "_ = plt.subplot(2, 2, 2), plt.imshow(gradient_orientation, vmin=-np.pi, vmax=np.pi, cmap='twilight'), plt.axis('off'), plt.title('Your Gradient Orientation')\n",
    "_ = plt.subplot(2, 2, 3), plt.imshow(gradient_magnitude_ref), plt.axis('off'), plt.title('Reference Gradient Magnitude')\n",
    "_ = plt.subplot(2, 2, 4), plt.imshow(gradient_orientation_ref, vmin=-np.pi, vmax=np.pi, cmap='twilight'), plt.axis('off'), plt.title('Reference Gradient Orientation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54fa58-b4c1-4275-a4c9-0c34d5fcca81",
   "metadata": {},
   "source": [
    "#### Section 2.1.2. Prewitt and Sobel Kernels\n",
    "While the derivative kernels shown above can work perfectly well for a noiseless image, they tend to give distorted outputs for noisy images. One way of countering this, is by applying a smoothing filter, i.e. a mean or gaussian blurring filter, in one direction; and then applying a derivative kernel in the other direction. These two consecutive filters can be represented by a single kernel, in the fashion shown below.\n",
    "\n",
    "![image](figures/prewitt.jpg)\n",
    "\n",
    "![image](figures/sobel.jpg)\n",
    "\n",
    "In the case where the smoothing kernel is a 3-radius averaging kernel, we call the resulting kernel a Prewitt kernel, and if a 3-radius gaussian kernel is used, we call it a Sobel kernel.\n",
    "\n",
    "Implement the constructor functions for these smooth derivation kernels, and see their results on a sample noisy image. Use a forward-difference derivation kernel, so Prewitt and Sobel kernels can be constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e38f2c-8d40-41a5-b949-b14202ecac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a noisy image\n",
    "image_noisy = gaussianNoise(image, 0.1)\n",
    "\n",
    "# Implementing a smooth derivative kernel constructor\n",
    "def smoothDerivativeKernel(direction : str, kernel_type : str, radius : int, sigma : float = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - direction : ['h' | 'v']\n",
    "        Determines the axis along which derivation takes place. 'h' for horizontal\n",
    "        and 'v' for vertical differentiation.\n",
    "    - kernel_type : ['g' | 'm']\n",
    "        Determines the type of the smoothing kernel. 'g' for gaussian, and 'm' for \n",
    "        mean.\n",
    "    - radius : int\n",
    "        Determines the radius of the smoothing kernel.\n",
    "    - sigma : float\n",
    "        Determines the sigma parameter for gaussian kernels.\n",
    "    Returns:\n",
    "    - kernel : np.ndarray\n",
    "        A kernel in np.ndarray format, with the specified characteristics and with\n",
    "        dtype=np.float64.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Creating horizontal Sobel kernels\n",
    "kernel_h = derivateKernel('h', 'f')\n",
    "kernel_h_smooth = smoothDerivativeKernel('h', 's', 3, 1)\n",
    "kernel_h_ref = derivateKernelRef('h', 'f')\n",
    "kernel_h_smooth_ref = smoothDerivativeKernelRef('h', 'g', 3, 1)\n",
    "\n",
    "edge_map = np.abs(cv.filter2D(image_noisy, cv.CV_64F, kernel_h))\n",
    "edge_map_smooth = np.abs(cv.filter2D(image_noisy, cv.CV_64F, kernel_h_smooth))\n",
    "edge_map_ref = np.abs(cv.filter2D(image_noisy, cv.CV_64F, kernel_h_ref))\n",
    "edge_map_smooth_ref = np.abs(cv.filter2D(image_noisy, cv.CV_64F, kernel_h_smooth_ref))\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(15, 15))\n",
    "_ = plt.subplot(2, 2, 1), plt.imshow(edge_map, vmin=0, vmax=1), plt.axis('off'), plt.title('Your  Edge Map')\n",
    "_ = plt.subplot(2, 2, 2), plt.imshow(edge_map_smooth, vmin=0, vmax=1), plt.axis('off'), plt.title('Your  Smoothed Edge Map')\n",
    "_ = plt.subplot(2, 2, 3), plt.imshow(edge_map_ref, vmin=0, vmax=1), plt.axis('off'), plt.title('Reference Edge Map')\n",
    "_ = plt.subplot(2, 2, 4), plt.imshow(edge_map_smooth_ref, vmin=0, vmax=1), plt.axis('off'), plt.title('Reference Smoothed Edge Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eedf759-1563-4f31-94f4-72d5a3455362",
   "metadata": {},
   "source": [
    "### Section 2.2. Second-Derivative Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c288a-95ca-40a0-ba04-9be992fd8d97",
   "metadata": {},
   "source": [
    "#### Section 2.2.1 Basic Second-Derivative Kernels\n",
    "Another way of detecting edges is by using a second derivative kernel. The second derivative, in discrete sequences is defined as follows:\n",
    "\n",
    "$ \\Large \\frac{\\partial I(t)}{\\partial t} = \\normalsize I(t-1) - 2I(t) + I(t+1)$\n",
    "\n",
    "In these filters, rather than the changes in pixel intensity, the *convexity* of pixel values is measured, and edges are marked with *zero-crossings*, i.e. parts of the image where the value of the second-derivative passes from negative to positive, or vice versa.\n",
    "\n",
    "Implement a second derivative kernel and see its effect on the sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcaabe5-91c8-46e2-a585-53fe729f7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a second derivative kernel constructor\n",
    "def secondDerivateKernel(direction : str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - direction : ['h' | 'v']\n",
    "        Determines the axis along which derivation takes place. 'h' for horizontal\n",
    "        and 'v' for vertical differentiation.\n",
    "    Returns:\n",
    "    - kernel : np.ndarray\n",
    "        A second derivative kernel in np.ndarray format, with the specified direction\n",
    "        and with dtype=np.float64.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Creating the kernels and applying the filter\n",
    "direction = 'h'\n",
    "kernel = secondDerivateKernel(direction)\n",
    "kernel_ref = secondDerivateKernelRef(direction)\n",
    "edge_map = cv.filter2D(image, cv.CV_64F, kernel)\n",
    "edge_map_ref = cv.filter2D(image, cv.CV_64F, kernel_ref)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(15, 15))\n",
    "_ = plt.subplot(2, 2, 1), plt.imshow(edge_map, vmin=-1, vmax=1), plt.axis('off'), plt.title('Your Second Derivative')\n",
    "_ = plt.subplot(2, 2, 2), plt.imshow(np.abs(edge_map), vmin=0, vmax=1), plt.axis('off'), plt.title('Magnitude of Your Second Derivative')\n",
    "_ = plt.subplot(2, 2, 3), plt.imshow(edge_map_ref, vmin=-1, vmax=1), plt.axis('off'), plt.title('Reference Second Derivative')\n",
    "_ = plt.subplot(2, 2, 4), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7622636b-add9-428f-ba5e-9155d306264b",
   "metadata": {},
   "source": [
    "#### Section 2.2.2 Laplacian Kernel\n",
    "A Laplace operator is defined as the sum of second derivatives of a function, with respect to the spatial variables. As such, for an image, the Laplacian would be as follows:\n",
    "\n",
    "$ \\nabla^2 I = \\Large \\frac{\\partial^2 I}{\\partial x^2} + \\frac{\\partial^2 I}{\\partial x^2} $\n",
    "\n",
    "Using this equation, a Laplacian kernel $L$ can be constructed as shown below.\n",
    "\n",
    "$\n",
    "L=\n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 \\\\\n",
    "1 & -4 & 1 \\\\\n",
    "0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "And a wider family of Laplacian kernels $L_\\alpha$ can be constructed, which might have different sensitivity towards diagonal edges.\n",
    "\n",
    "$\n",
    "L_\\alpha=\n",
    "\\begin{bmatrix}\n",
    "\\alpha & 1-\\alpha & \\alpha \\\\\n",
    "1-\\alpha & -4 & 1-\\alpha \\\\\n",
    "\\alpha & 1-\\alpha & \\alpha\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "Write a constructor function for a Laplacian kernel and see its effect on the sample image. Compare the results with what you saw with the second derivative kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98493168-e71d-42d8-9247-5bd2b0d5dc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a Laplacian kernel constructor\n",
    "def laplacianKernel(alpha : float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - alpha : float [0 1]\n",
    "        The alpha parameter in the Laplacian kernel.\n",
    "    Returns:\n",
    "    - kernel : np.ndarray\n",
    "        A Laplacian kernel in np.ndarray format, with the specified direction and\n",
    "        with dtype=np.float64.\n",
    "    \"\"\"\n",
    "    # ====== YOUR CODE ======\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Creating the kernels and applying the filter\n",
    "alpha = 0\n",
    "kernel = laplacianKernel(alpha)\n",
    "kernel_ref = laplacianKernelRef(alpha)\n",
    "edge_map = cv.filter2D(image, cv.CV_64F, kernel)\n",
    "edge_map_ref = cv.filter2D(image, cv.CV_64F, kernel_ref)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(15, 15))\n",
    "_ = plt.subplot(2, 2, 1), plt.imshow(edge_map, vmin=-1, vmax=1), plt.axis('off'), plt.title('Your Laplacian')\n",
    "_ = plt.subplot(2, 2, 2), plt.imshow(np.abs(edge_map), vmin=0, vmax=1), plt.axis('off'), plt.title('Magnitude of Your Laplacian')\n",
    "_ = plt.subplot(2, 2, 3), plt.imshow(edge_map_ref, vmin=-1, vmax=1), plt.axis('off'), plt.title('Reference Laplacian')\n",
    "_ = plt.subplot(2, 2, 4), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904293b-20e4-433c-8ad2-5e0f69d43006",
   "metadata": {},
   "source": [
    "**Note:** Filters such as Gaussian and mean, which preserve the global structure of the image while removing the smaller details are called *low-pass* filters. In contrast, filters like the derivatives which preserve the small-scale differences, but remove the large-scale features are called *low-pass* filters. You will learn more about such filters in the \"Frequency Filtering\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6b578-e74f-48b3-a3a8-dede990aa12b",
   "metadata": {},
   "source": [
    "## Section 3. Sharpening Filters\n",
    "As you saw above, filters can be used to extract low-frequency (coarse) or high-frequency (fine) details from an image. Using these extracted details, we can boost the fine details to create a sharper image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc54f1b4-d400-4cf0-a073-80d855add3ba",
   "metadata": {},
   "source": [
    "### Section 3.1. Sharpening with a Low-Pass filter\n",
    "One approach to image sharpening, is by using the difference between an image and its blurred version (either from an average or a Gaussian filter). Since the low-pass filter removes the fine features, its difference with the original image should be the high-frequency details of the image. Therefore, with an image $I$ and a low-pass filter $\\mathfrak{L}$, the sharpened image can be constructed using the following formula, where $c$ is a sharpening factor.\n",
    "\n",
    "$\n",
    "I_{sharp} = I + c \\cdot (I - \\mathfrak{L}[I]) = (1 + c) \\cdot I - c \\cdot \\mathfrak{L}[I]\n",
    "$\n",
    "\n",
    "Use one of the low-pass filters that you created in the previous sections to sharpen a blurred image with this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446cb17c-6f9f-44d1-97e4-a96490d55a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a blurred image\n",
    "image_blurred = cv.GaussianBlur(image, (7, 7), 2)\n",
    "\n",
    "# Setting the parameters\n",
    "c = 4\n",
    "\n",
    "# Creating the necessary objects for visualization\n",
    "image_lp = None # The image passed through a low-pass filter\n",
    "image_sharpened_lp = None # The sharpened image\n",
    "\n",
    "# ====== YOUR CODE ======\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "image_sharpened_lp_ref = sharpeningLPRef(image_blurred, c)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(15, 15))\n",
    "_ = plt.subplot(2, 2, 1), plt.imshow(image_sharpened_lp, vmin=0, vmax=1), plt.axis('off'), plt.title('Your Sharpened Image')\n",
    "_ = plt.subplot(2, 2, 2), plt.imshow(image_sharpened_lp_ref, vmin=0, vmax=1), plt.axis('off'), plt.title('Reference Sharpened Image')\n",
    "_ = plt.subplot(2, 2, 3), plt.imshow(image_blurred, vmin=0, vmax=1), plt.axis('off'), plt.title('Blurred Image')\n",
    "_ = plt.subplot(2, 2, 4), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83cbe42-c04b-40f2-9a72-ee99998464df",
   "metadata": {},
   "source": [
    "### Section 3.2. Unsharp Filtering\n",
    "Another approach to image sharpening is by subtracting the Laplacian of an image from itself. This results in a new kernel which is called the *unsharp* kernel.\n",
    "\n",
    "$\n",
    "K_{unsharp} =\n",
    "\\begin{bmatrix}\n",
    "0 & -1 & 0 \\\\\n",
    "-1 & 5 & -1 \\\\\n",
    "0 & -1 & 0\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "A demonstration of how subtracting the second derivative of a function from itself would result in a sharper function can be seen below.\n",
    "\n",
    "![image](figures/unsharp.jpg)\n",
    "\n",
    "Needless to say, any type of Laplacian kernel can be used to create an unsharp kernel, and any factor of the Laplacian can be subtracted from the original image, so that different levels of sharpening are achieved.\n",
    "\n",
    "Use a Laplacian kernel of your choice to sharpen an image via unsharp filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f5f22-3afa-4a4c-a565-329dd83361eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the parameters\n",
    "c = 4\n",
    "\n",
    "# Creating the necessary objects for visualization\n",
    "image_sharpened_unsharp = None # The sharpened image\n",
    "\n",
    "# ====== YOUR CODE ======\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "image_sharpened_unsharp_ref = sharpeningUnsharpRef(image_blurred, c)\n",
    "\n",
    "# Showing the results\n",
    "_ = plt.figure(figsize=(15, 15))\n",
    "_ = plt.subplot(2, 2, 1), plt.imshow(image_sharpened_unsharp, vmin=0, vmax=1), plt.axis('off'), plt.title('Your Sharpened Image')\n",
    "_ = plt.subplot(2, 2, 2), plt.imshow(image_sharpened_unsharp_ref, vmin=0, vmax=1), plt.axis('off'), plt.title('Reference Sharpened Image')\n",
    "_ = plt.subplot(2, 2, 3), plt.imshow(image_blurred, vmin=0, vmax=1), plt.axis('off'), plt.title('Blurred Image')\n",
    "_ = plt.subplot(2, 2, 4), plt.imshow(image, vmin=0, vmax=1), plt.axis('off'), plt.title('Original Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec619b9-c995-47fd-afa4-8a0de20bfdde",
   "metadata": {},
   "source": [
    "**Note:** You can see more variants of spatial filtering (harmonic, median, etc.) in the \"Noise Removal\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972a016-8b8a-4a91-9001-75f35d31a20c",
   "metadata": {},
   "source": [
    "# Scratchpad\n",
    "You can use this section to try out different codes, without making a mess in the notebook. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e07425f-2615-4ced-938b-44fd1d601605",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
